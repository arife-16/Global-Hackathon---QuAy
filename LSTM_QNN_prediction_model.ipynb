{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq8YozB7Sd-N",
        "outputId": "837e874b-f328-4f28-e087-24fe6b7ad87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m138.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m159.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install qiskit qiskit-aer matplotlib pandas numpy tensorflow pennylane --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stock Price Prediction with Quantum-Enhanced LSTM and QGAF\n",
        "\n",
        "This notebook presents a sophisticated approach to predicting stock prices, specifically the 'Close' price, by integrating classical Long Short-Term Memory (LSTM) networks with a novel Quantum Layer. The data is preprocessed using a variety of financial indicators and then fed into a dual-head model. A key innovation here is the use of a quantum-enhanced layer (though in the provided code, QGAF itself isn't explicitly implemented, the `QLayer` serves as a quantum-inspired enhancement). The model predicts the normalized return, `(Close - Open) / Open`, and then reconstructs the 'Close' price, ensuring it's clamped within the actual 'Low' and 'High' bounds of the day."
      ],
      "metadata": {
        "id": "ojrvIQaKSlJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "import pennylane as qml\n",
        "import os"
      ],
      "metadata": {
        "id": "vYA06DjgShQp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"X_train.csv\"\n",
        "TEST_PATH  = \"X_test.csv\"\n",
        "OUT_PATH   = \"predictions.csv\""
      ],
      "metadata": {
        "id": "DKphq0DPIN8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(train_path=TRAIN_PATH, test_path=TEST_PATH):\n",
        "    \"\"\"\n",
        "    Loads training and testing data from CSV files, converts 'Date' column to datetime,\n",
        "    and sorts the data by date.\n",
        "\n",
        "    Args:\n",
        "        train_path (str): Path to the training CSV file.\n",
        "        test_path (str): Path to the testing CSV file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two pandas DataFrames: train_df and test_df.\n",
        "    \"\"\"\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df  = pd.read_csv(test_path)\n",
        "    for df in (train_df, test_df):\n",
        "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "        df.sort_values(\"Date\", inplace=True)\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "2MroDEn4IRcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Technical Indicators and Lagged Features:\n",
        "\n",
        "- **High_Low**: Absolute difference between High and Low price.\n",
        "- **LogVolume**: Log-transformed trading volume, which can help normalize skewed volume data.\n",
        "- **Day of Week (DOW_sin, DOW_cos)**: Sinusoidal and cosinusoidal transformations of the day of the week to capture weekly seasonality.\n",
        "- **Returns (ret_5, ret_10)**: Log returns over 5 and 10 periods, indicating past price changes.\n",
        "- **Volatility (vol_5, vol_10)**: Standard deviation of log returns over 5 and 10 periods, measuring price fluctuation.\n",
        "- **EMA Gap (ema_gap)**: Difference between a fast and slow Exponential Moving Average (EMA), indicating momentum.\n",
        "- **Volume Z-score (vol_zscore)**: Z-score of volume relative to its 20-period mean and standard deviation, highlighting unusual volume activity.\n",
        "- **Month (month_sin, month_cos)**: Sinusoidal and cosinusoidal transformations of the month to capture annual seasonality.\n",
        "- **Average True Range (atr14)**: A measure of market volatility over 14 periods.\n",
        "- **Drawdown (drawdown_60)**: Percentage drop from the 60-period rolling maximum, indicating how far the price has fallen from a recent peak.\n",
        "- **Simple Moving Averages (SMA_5_lag1, SMA_10_lag1, SMA_20_lag1)**: Lagged Simple Moving Averages over various windows.\n",
        "- **Relative Strength Index (RSI_14_lag1)**: Lagged RSI over 14 periods, a momentum oscillator.\n",
        "- **Close_lag1, Close_lag2**: Lagged closing prices from the previous one and two days, providing direct historical price context."
      ],
      "metadata": {
        "id": "9SqI7IvqIbGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Target Variable Creation:\n",
        "\n",
        "The primary target variable is `r_norm = (Close - Open) / Open`, which represents the normalized return for the *next* day. This is shifted to ensure that features at time `t` are used to predict the return at time `t+1`.\n",
        "\n",
        "Additionally, two auxiliary target variables are created for the dual-head model:\n",
        "- `sign`: Binary indicator (1 if `r_norm > 0`, 0 otherwise) for directional prediction.\n",
        "- `mag`: Absolute value of `r_norm`, clipped to `[0, 1]` for magnitude prediction."
      ],
      "metadata": {
        "id": "WqbVVfnXIeyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rsi(series, window=14):\n",
        "    \"\"\"\n",
        "    Calculates the Relative Strength Index (RSI) for a given series.\n",
        "\n",
        "    Args:\n",
        "        series (pd.Series): The input price series (e.g., Close prices).\n",
        "        window (int): The lookback window for RSI calculation.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: The RSI values.\n",
        "    \"\"\"\n",
        "    delta = series.diff()\n",
        "    gain = delta.clip(lower=0).rolling(window=window, min_periods=window).mean()\n",
        "    loss = (-delta.clip(upper=0)).rolling(window=window, min_periods=window).mean().replace(0, 1e-6)\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def build_feature_frames(train_df, test_df, lookback=60, rsi_window=14, sma_windows=(5,10,20)):\n",
        "    \"\"\"\n",
        "    Engineers features and target variables for stock price prediction.\n",
        "\n",
        "    Args:\n",
        "        train_df (pd.DataFrame): Training DataFrame.\n",
        "        test_df (pd.DataFrame): Testing DataFrame.\n",
        "        lookback (int): The lookback window for sequence creation.\n",
        "        rsi_window (int): Window for RSI calculation.\n",
        "        sma_windows (tuple): Tuple of windows for SMA calculation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - X_train (np.array): Scaled training features.\n",
        "            - y_cls (np.array): Training labels for classification (direction).\n",
        "            - y_reg (np.array): Training labels for regression (magnitude).\n",
        "            - y_rnorm_full (np.array): Full normalized return for training.\n",
        "            - X_test_raw (pd.DataFrame): Raw test features.\n",
        "            - feat_scaler (StandardScaler): Fitted feature scaler.\n",
        "            - feats (list): List of feature names.\n",
        "            - train_eng (pd.DataFrame): Engineered training DataFrame.\n",
        "            - test_eng (pd.DataFrame): Engineered testing DataFrame.\n",
        "    \"\"\"\n",
        "    # Append test with Close as NaN to avoid leakage in target construction\n",
        "    combined = pd.concat(\n",
        "        [train_df.copy(), test_df.copy().assign(Close=np.nan)],\n",
        "        ignore_index=True\n",
        "    ).sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "    combined[\"High_Low\"]  = (combined[\"High\"] - combined[\"Low\"]).abs()\n",
        "    combined[\"LogVolume\"] = np.log1p(combined[\"Volume\"])\n",
        "\n",
        "    dow = combined[\"Date\"].dt.dayofweek.astype(float)\n",
        "    combined[\"DOW_sin\"] = np.sin(2*np.pi*dow/7.0)\n",
        "    combined[\"DOW_cos\"] = np.cos(2*np.pi*dow/7.0)\n",
        "\n",
        "    # Returns and vols based on Close where available\n",
        "    r1 = np.log(combined[\"Close\"] / combined[\"Close\"].shift(1))\n",
        "    combined[\"ret_5\"]  = r1.rolling(5).sum().shift(1)\n",
        "    combined[\"ret_10\"] = r1.rolling(10).sum().shift(1)\n",
        "    combined[\"vol_5\"]  = r1.rolling(5).std().shift(1)\n",
        "    combined[\"vol_10\"] = r1.rolling(10).std().shift(1)\n",
        "\n",
        "    ema_fast = combined[\"Close\"].ewm(span=5, adjust=False).mean()\n",
        "    ema_slow = combined[\"Close\"].ewm(span=20, adjust=False).mean()\n",
        "    combined[\"ema_gap\"] = ((ema_fast - ema_slow) / ema_slow).shift(1)\n",
        "\n",
        "    vmean20 = combined[\"Volume\"].rolling(20, min_periods=20).mean()\n",
        "    vstd20  = combined[\"Volume\"].rolling(20, min_periods=20).std()\n",
        "    combined[\"vol_zscore\"] = ((combined[\"Volume\"] - vmean20) / (vstd20.replace(0, np.nan))).shift(1)\n",
        "\n",
        "    combined[\"month_sin\"] = np.sin(2*np.pi*combined[\"Date\"].dt.month/12.0)\n",
        "    combined[\"month_cos\"] = np.cos(2*np.pi*combined[\"Date\"].dt.month/12.0)\n",
        "\n",
        "    tr = (combined[\"High\"] - combined[\"Low\"]).abs()\n",
        "    combined[\"atr14\"] = tr.rolling(14, min_periods=14).mean().shift(1)\n",
        "\n",
        "    roll_max_60 = combined[\"Close\"].shift(1).rolling(60, min_periods=60).max()\n",
        "    combined[\"drawdown_60\"] = (combined[\"Close\"].shift(1) / roll_max_60 - 1.0)\n",
        "\n",
        "    for w in sma_windows:\n",
        "        combined[f\"SMA_{w}_lag1\"] = combined[\"Close\"].rolling(w, min_periods=w).mean().shift(1)\n",
        "    combined[f\"RSI_{rsi_window}_lag1\"] = calculate_rsi(combined[\"Close\"], rsi_window).shift(1)\n",
        "\n",
        "    combined[\"Close_lag1\"] = combined[\"Close\"].shift(1)\n",
        "    combined[\"Close_lag2\"] = combined[\"Close\"].shift(2)\n",
        "\n",
        "    # Split engineered frame back into train and test views\n",
        "    max_train_date = train_df[\"Date\"].max()\n",
        "    train_eng = combined[combined[\"Date\"] <= max_train_date].copy()\n",
        "    test_eng  = combined[combined[\"Date\"] >  max_train_date].copy()\n",
        "\n",
        "    # Fill feature NaNs using only historical info per split\n",
        "    for df in (train_eng, test_eng):\n",
        "        df.ffill(inplace=True)\n",
        "        df.bfill(inplace=True)\n",
        "\n",
        "    base = [\"Open\",\"High\",\"Low\",\"Volume\"]\n",
        "    feats = base + [\n",
        "        \"High_Low\",\"LogVolume\",\"DOW_sin\",\"DOW_cos\",\n",
        "        \"Close_lag1\",\"Close_lag2\",\n",
        "        \"ret_5\",\"ret_10\",\"vol_5\",\"vol_10\",\"ema_gap\",\"vol_zscore\",\n",
        "        \"month_sin\",\"month_cos\",\"atr14\",\"drawdown_60\",\n",
        "        f\"RSI_{rsi_window}_lag1\"\n",
        "    ] + [f\"SMA_{w}_lag1\" for w in sma_windows]\n",
        "\n",
        "    # Target on train: r_norm = (Close - Open)/Open for next day\n",
        "    # Shift so features at t predict r_norm at t\n",
        "    r_norm = (train_df[\"Close\"] - train_df[\"Open\"]) / train_df[\"Open\"]\n",
        "    r_norm = r_norm.shift(-1).reindex(train_eng.index)  # align to train_eng rows\n",
        "    train_eng[\"r_norm\"] = r_norm\n",
        "\n",
        "    train_eng[\"sign\"] = (train_eng[\"r_norm\"] > 0).astype(np.float32)\n",
        "    train_eng[\"mag\"]  = train_eng[\"r_norm\"].abs().clip(0, 1.0)  # safe clip\n",
        "\n",
        "    train_eng = train_eng.dropna(subset=[\"r_norm\", \"sign\", \"mag\"])\n",
        "\n",
        "    X_train_raw = train_eng[feats].values.astype(np.float32)\n",
        "    y_cls = train_eng[\"sign\"].values.reshape(-1,1).astype(np.float32)\n",
        "    y_reg = train_eng[\"mag\"].values.reshape(-1,1).astype(np.float32)\n",
        "    y_rnorm_full = train_eng[\"r_norm\"].values.astype(np.float32).reshape(-1,1)\n",
        "\n",
        "    feat_scaler = StandardScaler()\n",
        "    X_train = feat_scaler.fit_transform(X_train_raw).astype(np.float32)\n",
        "\n",
        "    X_test_raw = test_eng[feats].copy().reset_index(drop=True)\n",
        "\n",
        "    return (X_train, y_cls, y_reg, y_rnorm_full,\n",
        "            X_test_raw, feat_scaler, feats, train_eng, test_eng)"
      ],
      "metadata": {
        "id": "JKN-aKuOIkWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Quantum Layer Implementation"
      ],
      "metadata": {
        "id": "Unc02D4OI46L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Components:\n",
        "\n",
        "- **`n_qubits`**: The number of qubits in the quantum circuit. This also corresponds to the input size for the quantum layer.\n",
        "- **`n_layers`**: The number of \"strongly entangling layers\" in the quantum circuit. More layers allow for more complex transformations.\n",
        "- **`qml.device(\"default.qubit\", wires=n_qubits)`**: Initializes a quantum simulator device from PennyLane.\n",
        "- **`circuit`**: The quantum circuit itself.\n",
        "    - `qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation=\"Y\")`: Encodes the classical input features into the quantum state by applying Y-rotations to each qubit.\n",
        "    - `qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))`: Applies a series of entangling and rotational gates, parameterized by `weights`. This is a common Ansatz for variational quantum circuits.\n",
        "    - `qml.expval(qml.PauliZ(0))`: Measures the expectation value of the Pauli-Z operator on the first qubit. This acts as the output of the quantum layer.\n",
        "- **`self.theta`**: Trainable weights for the `StronglyEntanglingLayers`. These weights are optimized during the model's training process, similar to classical neural network weights.\n",
        "- **`call(self, inputs)`**: This method defines the forward pass of the custom Keras layer. It takes the classical inputs, passes them to the quantum circuit (via `tf.vectorized_map` for batch processing), and returns the quantum output.\n",
        "\n",
        "While the original problem description mentions \"Quantum Gramian Angular Fields (QGAF)\", the provided `QLayer` directly uses `AngleEmbedding` and `StronglyEntanglingLayers`. QGAF is an encoding technique, and this `QLayer` can be seen as a quantum-enhanced feature extractor within the hybrid model."
      ],
      "metadata": {
        "id": "-EbOTd6dI33C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    A custom Keras layer that integrates a PennyLane quantum circuit.\n",
        "\n",
        "    Args:\n",
        "        n_qubits (int): Number of qubits in the quantum circuit.\n",
        "        n_layers (int): Number of strongly entangling layers in the circuit.\n",
        "        name (str): Name of the layer.\n",
        "        **kwargs: Additional keyword arguments for the Keras Layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qubits=4, n_layers=2, name=\"quantum_layer\", **kwargs):\n",
        "        super().__init__(name=name, dtype=tf.float32, **kwargs)\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_layers = n_layers\n",
        "        self.dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "        @qml.qnode(self.dev, interface=\"tf\", diff_method=\"parameter-shift\")\n",
        "        def circuit(inputs, weights):\n",
        "            \"\"\"\n",
        "            The quantum circuit architecture.\n",
        "            Inputs are embedded using AngleEmbedding, followed by strongly entangling layers.\n",
        "            The expectation value of PauliZ on the first qubit is returned.\n",
        "            \"\"\"\n",
        "            qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation=\"Y\")\n",
        "            qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "            return qml.expval(qml.PauliZ(0))\n",
        "        self.qnode = circuit\n",
        "\n",
        "        # Trainable weights for the strongly entangling layers\n",
        "        self.theta = self.add_weight(\n",
        "            name=\"weights\", shape=(n_layers, n_qubits, 3), # 3 parameters per CNOT-Ry-Rz block\n",
        "            initializer=tf.keras.initializers.RandomUniform(0.0, 2.0*np.pi),\n",
        "            trainable=True, dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass for the QLayer.\n",
        "        \"\"\"\n",
        "        x = tf.cast(inputs, tf.float32)\n",
        "        w = tf.cast(self.theta, tf.float32)\n",
        "        # Apply the quantum circuit to each item in the batch\n",
        "        out = tf.vectorized_map(lambda v: self.qnode(v, w), x)  # (batch,)\n",
        "        return tf.reshape(out, (-1,1)) # Reshape to (batch_size, 1)"
      ],
      "metadata": {
        "id": "L3FnZ1DEI6sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Dual-Head Model Architecture\n",
        "\n",
        "The `build_dual_head_model` function constructs the hybrid neural network. This model is designed with a \"dual-head\" approach, meaning it has two distinct output layers to predict different aspects of the target:\n",
        "1.  **Classification Head (`cls_out`)**: Predicts the direction of the price movement (up or down).\n",
        "2.  **Regression Head (`reg_out`)**: Predicts the magnitude of the price movement.\n",
        "\n",
        "### Model Flow:\n",
        "\n",
        "1.  **Input Layer**: Takes sequences of features with a defined `lookback` window.\n",
        "2.  **LSTM Layers**: Two LSTM layers process the sequential input data. LSTMs are well-suited for time series as they can learn long-term dependencies. `return_sequences=True` for the first LSTM means it outputs a sequence, while `return_sequences=False` for the second means it outputs a single vector representing the entire sequence. L2 regularization is applied to prevent overfitting.\n",
        "3.  **Trunk Dense Layer**: A `Dense` layer with ReLU activation acts as a feature extractor from the LSTM output.\n",
        "4.  **Quantum Branch**:\n",
        "    -   A `Dense` layer reduces the dimensionality of the `trunk` output to match the number of qubits (`n_qubits`), and applies a `tanh` activation to scale the inputs to the quantum layer.\n",
        "    -   The `QLayer` (our custom quantum-enhanced layer) processes these inputs.\n",
        "5.  **Concatenation**: The output of the `trunk` and the `QLayer` are concatenated, combining classical and quantum features.\n",
        "6.  **Classification Head**:\n",
        "    -   A `Dense` layer with ReLU activation processes the concatenated features.\n",
        "    -   A `Dropout` layer helps prevent overfitting.\n",
        "    -   The final `Dense` layer with `sigmoid` activation outputs a probability (for 'up' movement). `name=\"cls_out\"` identifies this output.\n",
        "7.  **Regression Head**:\n",
        "    -   Another `Dense` layer with ReLU activation processes the concatenated features.\n",
        "    -   The final `Dense` layer with `relu` activation outputs the magnitude of the normalized return. `name=\"reg_out\"` identifies this output.\n",
        "\n",
        "### Loss Functions and Optimizer:\n",
        "\n",
        "-   **`cls_out` Loss**: `BinaryCrossentropy` is used, suitable for binary classification (up/down).\n",
        "-   **`reg_out` Loss**: `Huber` loss is used, which is less sensitive to outliers than Mean Squared Error (MSE), making it suitable for regression tasks in financial data.\n",
        "-   **Loss Weights**: Both losses are weighted equally (1.0).\n",
        "-   **Optimizer**: Adam optimizer is used, a popular choice for deep learning, with a learning rate of `1e-3`.\n",
        "-   **Metrics**: Accuracy and AUC for classification, and Mean Absolute Error (MAE) for regression, are monitored."
      ],
      "metadata": {
        "id": "yZUkf6PxJbIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dual_head_model(lookback, n_features, n_qubits=4, n_layers=2, l2=1e-3, drop_cls=0.3):\n",
        "    \"\"\"\n",
        "    Builds a dual-head hybrid LSTM + Quantum model for stock price prediction.\n",
        "\n",
        "    Args:\n",
        "        lookback (int): The number of past time steps to consider.\n",
        "        n_features (int): The number of features per time step.\n",
        "        n_qubits (int): Number of qubits for the quantum layer.\n",
        "        n_layers (int): Number of layers in the quantum circuit.\n",
        "        l2 (float): L2 regularization strength.\n",
        "        drop_cls (float): Dropout rate for the classification head.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: The compiled Keras model.\n",
        "    \"\"\"\n",
        "    inp = layers.Input(shape=(lookback, n_features))\n",
        "    # LSTM layers for sequence processing\n",
        "    x = layers.LSTM(64, return_sequences=True,\n",
        "                    kernel_regularizer=regularizers.l2(l2),\n",
        "                    recurrent_regularizer=regularizers.l2(l2))(inp)\n",
        "    x = layers.LSTM(32, return_sequences=False, # Last LSTM output a single vector\n",
        "                    kernel_regularizer=regularizers.l2(l2),\n",
        "                    recurrent_regularizer=regularizers.l2(l2))(x)\n",
        "    trunk = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(l2))(x)\n",
        "\n",
        "    # Quantum branch\n",
        "    q_inp = layers.Dense(n_qubits, activation=\"tanh\", kernel_regularizer=regularizers.l2(l2))(trunk)\n",
        "    q_out = QLayer(n_qubits=n_qubits, n_layers=n_layers)(q_inp) # Our custom quantum layer\n",
        "    shared = layers.Concatenate()([trunk, q_out]) # Combine classical and quantum features\n",
        "\n",
        "    # Classification head (for direction prediction)\n",
        "    h1 = layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(l2))(shared)\n",
        "    h1 = layers.Dropout(drop_cls)(h1)\n",
        "    cls_out = layers.Dense(1, activation=\"sigmoid\", name=\"cls_out\")(h1) # Sigmoid for binary classification\n",
        "\n",
        "    # Regression head (for magnitude prediction)\n",
        "    h2 = layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(l2))(shared)\n",
        "    reg_out = layers.Dense(1, activation=\"relu\", name=\"reg_out\")(h2) # ReLU for positive magnitude\n",
        "\n",
        "    model = models.Model(inp, outputs=[cls_out, reg_out])\n",
        "    losses = {\"cls_out\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              \"reg_out\": tf.keras.losses.Huber(delta=0.5)} # Huber loss is less sensitive to outliers\n",
        "    loss_weights = {\"cls_out\": 1.0, \"reg_out\": 1.0} # Equal weighting for both losses\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(1e-3),\n",
        "        loss=losses,\n",
        "        loss_weights=loss_weights,\n",
        "        metrics={\"cls_out\": [tf.keras.metrics.BinaryAccuracy(name=\"acc\"), tf.keras.metrics.AUC(name=\"auc\")],\n",
        "                 \"reg_out\": [tf.keras.metrics.MeanAbsoluteError(name=\"mae\")]}\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "hwf7XyAvJY6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dual_sequences(X, y_cls, y_reg, y_rnorm, lookback):\n",
        "    \"\"\"\n",
        "    Creates sequences of features and corresponding dual targets for LSTM input.\n",
        "\n",
        "    Args:\n",
        "        X (np.array): Features array.\n",
        "        y_cls (np.array): Classification targets.\n",
        "        y_reg (np.array): Regression targets.\n",
        "        y_rnorm (np.array): Full normalized return targets.\n",
        "        lookback (int): The number of past time steps to include in each sequence.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - Xs (np.array): 3D array of feature sequences.\n",
        "            - Y_dict (dict): Dictionary of dual targets (classification and regression).\n",
        "            - yN (np.array): Full normalized return sequences.\n",
        "    \"\"\"\n",
        "    Xs, y1, y2, yN = [], [], [], []\n",
        "    N = len(X)\n",
        "    for i in range(N - lookback):\n",
        "        j = i + lookback\n",
        "        Xs.append(X[i:j]) # Features from i to j-1\n",
        "        y1.append(y_cls[j]) # Target at j\n",
        "        y2.append(y_reg[j]) # Target at j\n",
        "        yN.append(y_rnorm[j]) # Target at j\n",
        "    if not Xs: # Handle cases where sequences cannot be formed (e.g., data too short)\n",
        "        emptyX = np.empty((0, lookback, X.shape[1]), np.float32)\n",
        "        empty1 = np.empty((0, 1), np.float32)\n",
        "        return emptyX, {\"cls_out\": empty1, \"reg_out\": empty1}, empty1\n",
        "    return (np.asarray(Xs, np.float32),\n",
        "            {\"cls_out\": np.asarray(y1, np.float32),\n",
        "             \"reg_out\": np.asarray(y2, np.float32)},\n",
        "            np.asarray(yN, np.float32))\n",
        "\n",
        "def time_split_dual(X, y_cls, y_reg, y_rnorm, lookback, split=0.8):\n",
        "    \"\"\"\n",
        "    Splits the data into training and validation sets chronologically.\n",
        "\n",
        "    Args:\n",
        "        X (np.array): Features array.\n",
        "        y_cls (np.array): Classification targets.\n",
        "        y_reg (np.array): Regression targets.\n",
        "        y_rnorm (np.array): Full normalized return targets.\n",
        "        lookback (int): The lookback window for sequence creation.\n",
        "        split (float): Proportion of data to use for training (e.g., 0.8 for 80%).\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing (training sequences, validation sequences).\n",
        "    \"\"\"\n",
        "    n = len(X); k = int(split * n)\n",
        "    return (\n",
        "        create_dual_sequences(X[:k], y_cls[:k], y_reg[:k], y_rnorm[:k], lookback),\n",
        "        create_dual_sequences(X[k:],  y_cls[k:],  y_reg[k:],  y_rnorm[k:],  lookback),\n",
        "    )"
      ],
      "metadata": {
        "id": "MtLsRRYCJddD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_dual(model, X_tr_seq, Y_tr, X_va_seq, Y_va, epochs=120, batch=32):\n",
        "    \"\"\"\n",
        "    Trains the dual-head model with early stopping and learning rate reduction.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): The compiled Keras model.\n",
        "        X_tr_seq (np.array): Training feature sequences.\n",
        "        Y_tr (dict): Training targets for classification and regression.\n",
        "        X_va_seq (np.array): Validation feature sequences.\n",
        "        Y_va (dict): Validation targets for classification and regression.\n",
        "        epochs (int): Maximum number of training epochs.\n",
        "        batch (int): Batch size for training.\n",
        "    \"\"\"\n",
        "    es  = callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
        "    rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6)\n",
        "    model.fit(\n",
        "        X_tr_seq, Y_tr,\n",
        "        validation_data=(X_va_seq, Y_va) if len(X_va_seq) else None, # Only use validation if available\n",
        "        epochs=epochs, batch_size=batch, verbose=1, callbacks=[es, rlr]\n",
        "    )\n",
        "\n",
        "def sequence_return_metrics(model, X_seq, y_norm_seq):\n",
        "    \"\"\"\n",
        "    Calculates MSE and R-squared for the full normalized return (r_norm) on sequences.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): The trained Keras model.\n",
        "        X_seq (np.array): Feature sequences.\n",
        "        y_norm_seq (np.array): True normalized return sequences.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (MSE, R-squared, predicted r_norm)\n",
        "    \"\"\"\n",
        "    if len(X_seq) == 0:\n",
        "        return None, None, None\n",
        "    p_up, mag = model.predict(X_seq, verbose=0)\n",
        "    # Reconstruct r_norm prediction from directional probability and magnitude\n",
        "    r_norm_pred = (2.0 * p_up - 1.0) * mag\n",
        "    mse = mean_squared_error(y_norm_seq, r_norm_pred)\n",
        "    r2  = r2_score(y_norm_seq, r_norm_pred)\n",
        "    return mse, r2, r_norm_pred"
      ],
      "metadata": {
        "id": "mW9GdlXMJqhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Dual-head Hybrid LSTM + Quantum (TensorFlow/PennyLane) predicting normalized return r_norm = (Close - Open)/Open.\n",
        "Then reconstructs Close for the test set and clamps each prediction to [Low, High].\n",
        "\n",
        "- Two heads:\n",
        "    * cls_out: direction, BCE loss on 1{r_norm > 0}\n",
        "    * reg_out: magnitude, Huber loss on |r_norm|\n",
        "- Reports Train/Val MSE on r_norm.\n",
        "- Writes predictions.csv with {Date, Close}. Plots predicted Close and High–Low band.\n",
        "\n",
        "Inputs: X_train.csv, X_test.csv with columns: Date, Open, High, Low, Close, Volume\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers, regularizers\n",
        "import pennylane as qml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import argparse, warnings, matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "TRAIN_PATH = \"X_train.csv\"\n",
        "TEST_PATH  = \"X_test.csv\"\n",
        "OUT_PATH   = \"predictions.csv\"\n",
        "\n",
        "# ============ IO ============\n",
        "def load_data(train_path=TRAIN_PATH, test_path=TEST_PATH):\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df  = pd.read_csv(test_path)\n",
        "    for df in (train_df, test_df):\n",
        "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "        df.sort_values(\"Date\", inplace=True)\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "    return train_df, test_df\n",
        "\n",
        "# ============ Indicators ============\n",
        "def calculate_rsi(series, window=14):\n",
        "    delta = series.diff()\n",
        "    gain = delta.clip(lower=0).rolling(window=window, min_periods=window).mean()\n",
        "    loss = (-delta.clip(upper=0)).rolling(window=window, min_periods=window).mean().replace(0, 1e-6)\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "# ============ Features + Targets ============\n",
        "def build_feature_frames(train_df, test_df, lookback=60, rsi_window=14, sma_windows=(5,10,20)):\n",
        "    # Append test with Close as NaN to avoid leakage in target construction\n",
        "    combined = pd.concat(\n",
        "        [train_df.copy(), test_df.copy().assign(Close=np.nan)],\n",
        "        ignore_index=True\n",
        "    ).sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "    combined[\"High_Low\"]  = (combined[\"High\"] - combined[\"Low\"]).abs()\n",
        "    combined[\"LogVolume\"] = np.log1p(combined[\"Volume\"])\n",
        "\n",
        "    dow = combined[\"Date\"].dt.dayofweek.astype(float)\n",
        "    combined[\"DOW_sin\"] = np.sin(2*np.pi*dow/7.0)\n",
        "    combined[\"DOW_cos\"] = np.cos(2*np.pi*dow/7.0)\n",
        "\n",
        "    # Returns and vols based on Close where available\n",
        "    r1 = np.log(combined[\"Close\"] / combined[\"Close\"].shift(1))\n",
        "    combined[\"ret_5\"]  = r1.rolling(5).sum().shift(1)\n",
        "    combined[\"ret_10\"] = r1.rolling(10).sum().shift(1)\n",
        "    combined[\"vol_5\"]  = r1.rolling(5).std().shift(1)\n",
        "    combined[\"vol_10\"] = r1.rolling(10).std().shift(1)\n",
        "\n",
        "    ema_fast = combined[\"Close\"].ewm(span=5, adjust=False).mean()\n",
        "    ema_slow = combined[\"Close\"].ewm(span=20, adjust=False).mean()\n",
        "    combined[\"ema_gap\"] = ((ema_fast - ema_slow) / ema_slow).shift(1)\n",
        "\n",
        "    vmean20 = combined[\"Volume\"].rolling(20, min_periods=20).mean()\n",
        "    vstd20  = combined[\"Volume\"].rolling(20, min_periods=20).std()\n",
        "    combined[\"vol_zscore\"] = ((combined[\"Volume\"] - vmean20) / (vstd20.replace(0, np.nan))).shift(1)\n",
        "\n",
        "    combined[\"month_sin\"] = np.sin(2*np.pi*combined[\"Date\"].dt.month/12.0)\n",
        "    combined[\"month_cos\"] = np.cos(2*np.pi*combined[\"Date\"].dt.month/12.0)\n",
        "\n",
        "    tr = (combined[\"High\"] - combined[\"Low\"]).abs()\n",
        "    combined[\"atr14\"] = tr.rolling(14, min_periods=14).mean().shift(1)\n",
        "\n",
        "    roll_max_60 = combined[\"Close\"].shift(1).rolling(60, min_periods=60).max()\n",
        "    combined[\"drawdown_60\"] = (combined[\"Close\"].shift(1) / roll_max_60 - 1.0)\n",
        "\n",
        "    for w in sma_windows:\n",
        "        combined[f\"SMA_{w}_lag1\"] = combined[\"Close\"].rolling(w, min_periods=w).mean().shift(1)\n",
        "    combined[f\"RSI_{rsi_window}_lag1\"] = calculate_rsi(combined[\"Close\"], rsi_window).shift(1)\n",
        "\n",
        "    combined[\"Close_lag1\"] = combined[\"Close\"].shift(1)\n",
        "    combined[\"Close_lag2\"] = combined[\"Close\"].shift(2)\n",
        "\n",
        "    # Split engineered frame back into train and test views\n",
        "    max_train_date = train_df[\"Date\"].max()\n",
        "    train_eng = combined[combined[\"Date\"] <= max_train_date].copy()\n",
        "    test_eng  = combined[combined[\"Date\"] >  max_train_date].copy()\n",
        "\n",
        "    # Fill feature NaNs using only historical info per split\n",
        "    for df in (train_eng, test_eng):\n",
        "        df.ffill(inplace=True)\n",
        "        df.bfill(inplace=True)\n",
        "\n",
        "    base = [\"Open\",\"High\",\"Low\",\"Volume\"]\n",
        "    feats = base + [\n",
        "        \"High_Low\",\"LogVolume\",\"DOW_sin\",\"DOW_cos\",\n",
        "        \"Close_lag1\",\"Close_lag2\",\n",
        "        \"ret_5\",\"ret_10\",\"vol_5\",\"vol_10\",\"ema_gap\",\"vol_zscore\",\n",
        "        \"month_sin\",\"month_cos\",\"atr14\",\"drawdown_60\",\n",
        "        f\"RSI_{rsi_window}_lag1\"\n",
        "    ] + [f\"SMA_{w}_lag1\" for w in sma_windows]\n",
        "\n",
        "    # Target on train: r_norm = (Close - Open)/Open for next day\n",
        "    # Shift so features at t predict r_norm at t\n",
        "    r_norm = (train_df[\"Close\"] - train_df[\"Open\"]) / train_df[\"Open\"]\n",
        "    r_norm = r_norm.shift(-1).reindex(train_eng.index)  # align to train_eng rows\n",
        "    train_eng[\"r_norm\"] = r_norm\n",
        "\n",
        "    train_eng[\"sign\"] = (train_eng[\"r_norm\"] > 0).astype(np.float32)\n",
        "    train_eng[\"mag\"]  = train_eng[\"r_norm\"].abs().clip(0, 1.0)  # safe clip\n",
        "\n",
        "    train_eng = train_eng.dropna(subset=[\"r_norm\", \"sign\", \"mag\"])\n",
        "\n",
        "    X_train_raw = train_eng[feats].values.astype(np.float32)\n",
        "    y_cls = train_eng[\"sign\"].values.reshape(-1,1).astype(np.float32)\n",
        "    y_reg = train_eng[\"mag\"].values.reshape(-1,1).astype(np.float32)\n",
        "    y_rnorm_full = train_eng[\"r_norm\"].values.astype(np.float32).reshape(-1,1)\n",
        "\n",
        "    feat_scaler = StandardScaler()\n",
        "    X_train = feat_scaler.fit_transform(X_train_raw).astype(np.float32)\n",
        "\n",
        "    X_test_raw = test_eng[feats].copy().reset_index(drop=True)\n",
        "\n",
        "    return (X_train, y_cls, y_reg, y_rnorm_full,\n",
        "            X_test_raw, feat_scaler, feats, train_eng, test_eng)\n",
        "\n",
        "# ============ Quantum layer (TF-only) ============\n",
        "class QLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_qubits=4, n_layers=2, name=\"quantum_layer\", **kwargs):\n",
        "        super().__init__(name=name, dtype=tf.float32, **kwargs)\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_layers = n_layers\n",
        "        self.dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "        @qml.qnode(self.dev, interface=\"tf\", diff_method=\"parameter-shift\")\n",
        "        def circuit(inputs, weights):\n",
        "            qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation=\"Y\")\n",
        "            qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "            return qml.expval(qml.PauliZ(0))\n",
        "        self.qnode = circuit\n",
        "\n",
        "        self.theta = self.add_weight(\n",
        "            name=\"weights\", shape=(n_layers, n_qubits, 3),\n",
        "            initializer=tf.keras.initializers.RandomUniform(0.0, 2.0*np.pi),\n",
        "            trainable=True, dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = tf.cast(inputs, tf.float32)\n",
        "        w = tf.cast(self.theta, tf.float32)\n",
        "        out = tf.vectorized_map(lambda v: self.qnode(v, w), x)  # (batch,)\n",
        "        return tf.reshape(out, (-1,1))\n",
        "\n",
        "# ============ Dual-head model ============\n",
        "def build_dual_head_model(lookback, n_features, n_qubits=4, n_layers=2, l2=1e-3, drop_cls=0.3):\n",
        "    inp = layers.Input(shape=(lookback, n_features))\n",
        "    x = layers.LSTM(64, return_sequences=True,\n",
        "                    kernel_regularizer=regularizers.l2(l2),\n",
        "                    recurrent_regularizer=regularizers.l2(l2))(inp)\n",
        "    x = layers.LSTM(32, return_sequences=False,\n",
        "                    kernel_regularizer=regularizers.l2(l2),\n",
        "                    recurrent_regularizer=regularizers.l2(l2))(x)\n",
        "    trunk = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(l2))(x)\n",
        "\n",
        "    q_inp = layers.Dense(n_qubits, activation=\"tanh\", kernel_regularizer=regularizers.l2(l2))(trunk)\n",
        "    q_out = QLayer(n_qubits=n_qubits, n_layers=n_layers)(q_inp)\n",
        "    shared = layers.Concatenate()([trunk, q_out])\n",
        "\n",
        "    h1 = layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(l2))(shared)\n",
        "    h1 = layers.Dropout(drop_cls)(h1)\n",
        "    cls_out = layers.Dense(1, activation=\"sigmoid\", name=\"cls_out\")(h1)\n",
        "\n",
        "    h2 = layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(l2))(shared)\n",
        "    reg_out = layers.Dense(1, activation=\"relu\", name=\"reg_out\")(h2)\n",
        "\n",
        "    model = models.Model(inp, outputs=[cls_out, reg_out])\n",
        "    losses = {\"cls_out\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              \"reg_out\": tf.keras.losses.Huber(delta=0.5)}\n",
        "    loss_weights = {\"cls_out\": 1.0, \"reg_out\": 1.0}\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(1e-3),\n",
        "        loss=losses,\n",
        "        loss_weights=loss_weights,\n",
        "        metrics={\"cls_out\": [tf.keras.metrics.BinaryAccuracy(name=\"acc\"), tf.keras.metrics.AUC(name=\"auc\")],\n",
        "                 \"reg_out\": [tf.keras.metrics.MeanAbsoluteError(name=\"mae\")]}\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# ============ Sequencing ============\n",
        "def create_dual_sequences(X, y_cls, y_reg, y_rnorm, lookback):\n",
        "    Xs, y1, y2, yN = [], [], [], []\n",
        "    N = len(X)\n",
        "    for i in range(N - lookback):\n",
        "        j = i + lookback\n",
        "        Xs.append(X[i:j])\n",
        "        y1.append(y_cls[j])\n",
        "        y2.append(y_reg[j])\n",
        "        yN.append(y_rnorm[j])\n",
        "    if not Xs:\n",
        "        emptyX = np.empty((0, lookback, X.shape[1]), np.float32)\n",
        "        empty1 = np.empty((0, 1), np.float32)\n",
        "        return emptyX, {\"cls_out\": empty1, \"reg_out\": empty1}, empty1\n",
        "    return (np.asarray(Xs, np.float32),\n",
        "            {\"cls_out\": np.asarray(y1, np.float32),\n",
        "             \"reg_out\": np.asarray(y2, np.float32)},\n",
        "            np.asarray(yN, np.float32))\n",
        "\n",
        "def time_split_dual(X, y_cls, y_reg, y_rnorm, lookback, split=0.8):\n",
        "    n = len(X); k = int(split * n)\n",
        "    return (\n",
        "        create_dual_sequences(X[:k], y_cls[:k], y_reg[:k], y_rnorm[:k], lookback),\n",
        "        create_dual_sequences(X[k:],  y_cls[k:],  y_reg[k:],  y_rnorm[k:],  lookback),\n",
        "    )\n",
        "\n",
        "# ============ Training ============\n",
        "def fit_dual(model, X_tr_seq, Y_tr, X_va_seq, Y_va, epochs=120, batch=32):\n",
        "    es  = callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
        "    rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6)\n",
        "    model.fit(\n",
        "        X_tr_seq, Y_tr,\n",
        "        validation_data=(X_va_seq, Y_va) if len(X_va_seq) > 0 else None, # Check if validation data exists\n",
        "        epochs=epochs, batch_size=batch, verbose=1, callbacks=[es, rlr]\n",
        "    )\n",
        "\n",
        "# ============ Sequence metrics on r_norm ============\n",
        "def sequence_return_metrics(model, X_seq, y_norm_seq):\n",
        "    if len(X_seq) == 0:\n",
        "        return None, None\n",
        "    p_up, mag = model.predict(X_seq, verbose=0)\n",
        "    r_norm_pred = (2.0 * p_up - 1.0) * mag\n",
        "    mse = mean_squared_error(y_norm_seq, r_norm_pred)\n",
        "    return mse, r_norm_pred\n",
        "\n",
        "# ============ Recursive reconstruction to Close with clamping ============\n",
        "def recursive_predict_close_norm(model, X_train_tail, X_test_raw_df, feat_scaler, feats,\n",
        "                                 lookback, beta=1.0):\n",
        "    \"\"\"\n",
        "    Uses predicted r_norm_t to compute Close_t = Open_t * (1 + r_norm_t).\n",
        "    Clamps each Close_t to [Low_t, High_t].\n",
        "    Maintains Close_lag1 and Close_lag2 during the walk-forward.\n",
        "    \"\"\"\n",
        "    buf = X_train_tail.copy()\n",
        "    test_raw = X_test_raw_df.copy()\n",
        "    n = len(test_raw)\n",
        "    preds_close = np.zeros((n,1), np.float64)\n",
        "\n",
        "    # Seed prior closes using last available values from training if present in features\n",
        "    prev_close = float(test_raw.get(\"Close_lag1\", pd.Series([np.nan])).iloc[0]) if \"Close_lag1\" in test_raw.columns else np.nan\n",
        "    prev_prev  = float(test_raw.get(\"Close_lag2\", pd.Series([np.nan])).iloc[0]) if \"Close_lag2\" in test_raw.columns else np.nan\n",
        "\n",
        "    for t in range(n):\n",
        "        # Update lag features with our own predictions\n",
        "        if \"Close_lag2\" in test_raw.columns and not np.isnan(prev_prev):\n",
        "            test_raw.iat[t, test_raw.columns.get_loc(\"Close_lag2\")] = prev_prev\n",
        "        if \"Close_lag1\" in test_raw.columns and not np.isnan(prev_close):\n",
        "            test_raw.iat[t, test_raw.columns.get_loc(\"Close_lag1\")] = prev_close\n",
        "\n",
        "        row = test_raw.iloc[t][feats].values.astype(np.float32)[None, :]\n",
        "        row_s = feat_scaler.transform(row).astype(np.float32)\n",
        "\n",
        "        buf = np.vstack([buf[1:], row_s])\n",
        "        seq = buf.reshape(1, lookback, -1)\n",
        "\n",
        "        p_up, mag = model.predict(seq, verbose=0)\n",
        "        r_norm = (2.0 * float(p_up[0,0]) - 1.0) * float(mag[0,0]) * float(beta)\n",
        "\n",
        "        o  = float(test_raw.iloc[t][\"Open\"])\n",
        "        lo = float(test_raw.iloc[t][\"Low\"])\n",
        "        hi = float(test_raw.iloc[t][\"High\"])\n",
        "\n",
        "        c_hat = o * (1.0 + r_norm)\n",
        "        c_hat = np.clip(c_hat, lo, hi)  # clamp to [Low, High]\n",
        "\n",
        "        preds_close[t,0] = c_hat\n",
        "        prev_prev, prev_close = prev_close, c_hat\n",
        "\n",
        "    return preds_close\n",
        "\n",
        "# ============ Plot ============\n",
        "def plot_predictions(pred_df, test_df):\n",
        "    pred_df = pred_df.copy()\n",
        "    pred_df[\"Date\"] = pd.to_datetime(pred_df[\"Date\"])\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.plot(pred_df[\"Date\"], pred_df[\"Close\"], label=\"Predicted Close\", linewidth=2, marker=\"o\", ms=3)\n",
        "    if {\"High\",\"Low\",\"Date\"}.issubset(test_df.columns):\n",
        "        env = test_df[[\"Date\",\"Low\",\"High\"]].copy()\n",
        "        env[\"Date\"] = pd.to_datetime(env[\"Date\"])\n",
        "        plt.fill_between(env[\"Date\"], env[\"Low\"], env[\"High\"], alpha=0.2, label=\"Actual High–Low Range\", color=\"gray\")\n",
        "    plt.title(\"Predicted Close vs. Actual High–Low Range (Test Set)\")\n",
        "    plt.xlabel(\"Date\"); plt.ylabel(\"Price\"); plt.grid(True, ls=\"--\", alpha=0.6); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "# ============ Main ============\n",
        "def main():\n",
        "    defaults = dict(lookback=60, epochs=120, batch=32, qubits=4, layers=2, l2=1e-3, dropout=0.3, plot=True)\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--lookback\", type=int, default=defaults[\"lookback\"])\n",
        "    parser.add_argument(\"--epochs\", type=int, default=defaults[\"epochs\"])\n",
        "    parser.add_argument(\"--batch\", type=int, default=defaults[\"batch\"])\n",
        "    parser.add_argument(\"--qubits\", type=int, default=defaults[\"qubits\"])\n",
        "    parser.add_argument(\"--layers\", type=int, default=defaults[\"layers\"])\n",
        "    parser.add_argument(\"--l2\", type=float, default=defaults[\"l2\"])\n",
        "    parser.add_argument(\"--dropout\", type=float, default=defaults[\"dropout\"])\n",
        "    parser.add_argument(\"--plot\", action=\"store_true\")\n",
        "    try:\n",
        "        args, _ = parser.parse_known_args()\n",
        "    except SystemExit:\n",
        "        args = argparse.Namespace(**defaults)\n",
        "\n",
        "    np.random.seed(42); tf.random.set_seed(42)\n",
        "\n",
        "    train_df, test_df = load_data()\n",
        "    (X_train, y_cls, y_reg, y_rnorm_full,\n",
        "     X_test_raw, feat_scaler, feats, train_eng, test_eng) = build_feature_frames(\n",
        "        train_df, test_df, lookback=args.lookback, rsi_window=14, sma_windows=(5,10,20)\n",
        "    )\n",
        "\n",
        "    # Split and build aligned sequences\n",
        "    (X_tr_seq, Y_tr, y_true_tr_norm), (X_va_seq, Y_va, y_true_va_norm) = time_split_dual(\n",
        "        X_train, y_cls, y_reg, y_rnorm_full, args.lookback, split=0.8\n",
        "    )\n",
        "    n_features = X_train.shape[1]\n",
        "\n",
        "    # Model\n",
        "    model = build_dual_head_model(args.lookback, n_features, n_qubits=args.qubits, n_layers=args.layers, l2=args.l2, drop_cls=args.dropout)\n",
        "    print(\"\\nModel summary:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Train\n",
        "    fit_dual(model, X_tr_seq, Y_tr, X_va_seq, Y_va, epochs=args.epochs, batch=args.batch)\n",
        "\n",
        "    # Report Train MSE on r_norm\n",
        "    train_metrics = sequence_return_metrics(model, X_tr_seq, y_true_tr_norm)\n",
        "    if train_metrics is not None:\n",
        "        tr_mse, _ = train_metrics\n",
        "        print(f\"Train r_norm MSE: {tr_mse:.6f}\")\n",
        "\n",
        "    # Report Val MSE\n",
        "    beta = 1.0\n",
        "    val_metrics = sequence_return_metrics(model, X_va_seq, y_true_va_norm)\n",
        "    if val_metrics is not None:\n",
        "        va_mse, r_pred_va = val_metrics\n",
        "        print(f\"Val   r_norm MSE: {va_mse:.6f}\")\n",
        "        num = float((r_pred_va * y_true_va_norm).sum())\n",
        "        den = float((r_pred_va * r_pred_va).sum()) or 1.0\n",
        "        beta = num / den\n",
        "        print(f\"Calibrated amplitude beta (val): {beta:.3f}\")\n",
        "\n",
        "    # Directional accuracy on train sequences\n",
        "    if len(X_tr_seq):\n",
        "        p_up_tr, _ = model.predict(X_tr_seq, verbose=0)\n",
        "        dir_acc = ((p_up_tr >= 0.5).astype(np.float32) == Y_tr[\"cls_out\"]).mean()\n",
        "        print(f\"Train Directional Accuracy: {dir_acc:.3f}\")\n",
        "\n",
        "    # Recursive forecast to Close on test set with clamp\n",
        "    seed_tail = X_train[-args.lookback:, :]\n",
        "    preds_close = recursive_predict_close_norm(\n",
        "        model, seed_tail, X_test_raw, feat_scaler, feats, args.lookback, beta=beta\n",
        "    )\n",
        "    pred_df = pd.DataFrame({\"Date\": test_df[\"Date\"].values, \"Close\": preds_close.squeeze()})\n",
        "    pred_df.to_csv(OUT_PATH, index=False)\n",
        "    print(f\"Saved {OUT_PATH} with {len(pred_df)} rows.\")\n",
        "\n",
        "    if args.plot:\n",
        "        plot_predictions(pred_df, test_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ujQ066GOELcG",
        "outputId": "c3e917a8-6b0f-4624-fcf5-193a9b6620f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting PyFunc cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m24\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m22,784\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m12,416\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m260\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ quantum_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m24\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mQLayer\u001b[0m)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ quantum_layer[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cls_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reg_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,784</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ quantum_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QLayer</span>)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ quantum_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cls_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reg_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,886\u001b[0m (163.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,886</span> (163.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,886\u001b[0m (163.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,886</span> (163.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting PyFunc cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting PyFunc cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - cls_out_acc: 0.4558 - cls_out_auc: 0.4452 - cls_out_loss: 0.7023 - loss: 1.0630 - reg_out_loss: 2.9557e-04 - reg_out_mae: 0.0158 - learning_rate: 0.0010\n",
            "Epoch 2/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - cls_out_acc: 0.4809 - cls_out_auc: 0.5367 - cls_out_loss: 0.6912 - loss: 1.0415 - reg_out_loss: 2.6445e-04 - reg_out_mae: 0.0171 - learning_rate: 0.0010\n",
            "Epoch 3/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - cls_out_acc: 0.5802 - cls_out_auc: 0.5361 - cls_out_loss: 0.6833 - loss: 1.0226 - reg_out_loss: 2.7288e-04 - reg_out_mae: 0.0173 - learning_rate: 0.0010\n",
            "Epoch 4/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - cls_out_acc: 0.6216 - cls_out_auc: 0.5424 - cls_out_loss: 0.6732 - loss: 1.0073 - reg_out_loss: 1.7223e-04 - reg_out_mae: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 5/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - cls_out_acc: 0.6544 - cls_out_auc: 0.6008 - cls_out_loss: 0.6667 - loss: 0.9917 - reg_out_loss: 1.3446e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 6/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - cls_out_acc: 0.5950 - cls_out_auc: 0.5583 - cls_out_loss: 0.6652 - loss: 0.9851 - reg_out_loss: 1.4573e-04 - reg_out_mae: 0.0100 - learning_rate: 0.0010\n",
            "Epoch 7/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - cls_out_acc: 0.5950 - cls_out_auc: 0.5186 - cls_out_loss: 0.6730 - loss: 0.9882 - reg_out_loss: 1.4679e-04 - reg_out_mae: 0.0099 - learning_rate: 0.0010\n",
            "Epoch 8/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - cls_out_acc: 0.6060 - cls_out_auc: 0.6146 - cls_out_loss: 0.6651 - loss: 0.9678 - reg_out_loss: 1.3411e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 9/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - cls_out_acc: 0.5841 - cls_out_auc: 0.5907 - cls_out_loss: 0.6617 - loss: 0.9578 - reg_out_loss: 1.3450e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 10/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - cls_out_acc: 0.5872 - cls_out_auc: 0.5672 - cls_out_loss: 0.6763 - loss: 0.9692 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 11/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - cls_out_acc: 0.6028 - cls_out_auc: 0.6312 - cls_out_loss: 0.6464 - loss: 0.9339 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 12/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - cls_out_acc: 0.6325 - cls_out_auc: 0.5920 - cls_out_loss: 0.6562 - loss: 0.9396 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 13/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - cls_out_acc: 0.6325 - cls_out_auc: 0.6221 - cls_out_loss: 0.6564 - loss: 0.9308 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 14/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - cls_out_acc: 0.6435 - cls_out_auc: 0.6383 - cls_out_loss: 0.6385 - loss: 0.9048 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 15/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - cls_out_acc: 0.6216 - cls_out_auc: 0.6089 - cls_out_loss: 0.6354 - loss: 0.9041 - reg_out_loss: 1.3572e-04 - reg_out_mae: 0.0089 - learning_rate: 0.0010\n",
            "Epoch 16/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - cls_out_acc: 0.6028 - cls_out_auc: 0.5716 - cls_out_loss: 0.6601 - loss: 0.9236 - reg_out_loss: 1.6035e-04 - reg_out_mae: 0.0106 - learning_rate: 0.0010\n",
            "Epoch 17/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - cls_out_acc: 0.6325 - cls_out_auc: 0.6467 - cls_out_loss: 0.6358 - loss: 0.8947 - reg_out_loss: 1.8101e-04 - reg_out_mae: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 18/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - cls_out_acc: 0.6435 - cls_out_auc: 0.5983 - cls_out_loss: 0.6553 - loss: 0.9014 - reg_out_loss: 1.6708e-04 - reg_out_mae: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 19/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - cls_out_acc: 0.6247 - cls_out_auc: 0.6307 - cls_out_loss: 0.6445 - loss: 0.8890 - reg_out_loss: 1.3554e-04 - reg_out_mae: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 20/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - cls_out_acc: 0.6505 - cls_out_auc: 0.6503 - cls_out_loss: 0.6446 - loss: 0.8877 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 21/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - cls_out_acc: 0.5536 - cls_out_auc: 0.5692 - cls_out_loss: 0.6706 - loss: 0.9060 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 22/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - cls_out_acc: 0.5544 - cls_out_auc: 0.6032 - cls_out_loss: 0.6456 - loss: 0.8803 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 23/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - cls_out_acc: 0.6403 - cls_out_auc: 0.6658 - cls_out_loss: 0.6262 - loss: 0.8535 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 24/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - cls_out_acc: 0.5841 - cls_out_auc: 0.6289 - cls_out_loss: 0.6448 - loss: 0.8720 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 25/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - cls_out_acc: 0.6028 - cls_out_auc: 0.5810 - cls_out_loss: 0.6615 - loss: 0.8893 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 26/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - cls_out_acc: 0.6208 - cls_out_auc: 0.6090 - cls_out_loss: 0.6628 - loss: 0.8850 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 27/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - cls_out_acc: 0.6208 - cls_out_auc: 0.6293 - cls_out_loss: 0.6405 - loss: 0.8583 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 28/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - cls_out_acc: 0.6427 - cls_out_auc: 0.6392 - cls_out_loss: 0.6228 - loss: 0.8443 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 29/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - cls_out_acc: 0.6435 - cls_out_auc: 0.6603 - cls_out_loss: 0.6305 - loss: 0.8447 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 30/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - cls_out_acc: 0.6099 - cls_out_auc: 0.6335 - cls_out_loss: 0.6376 - loss: 0.8457 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 31/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - cls_out_acc: 0.6498 - cls_out_auc: 0.6231 - cls_out_loss: 0.6362 - loss: 0.8522 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 32/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - cls_out_acc: 0.6396 - cls_out_auc: 0.6810 - cls_out_loss: 0.6037 - loss: 0.8145 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 33/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - cls_out_acc: 0.6498 - cls_out_auc: 0.6372 - cls_out_loss: 0.6341 - loss: 0.8354 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 34/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - cls_out_acc: 0.6200 - cls_out_auc: 0.6758 - cls_out_loss: 0.6056 - loss: 0.8144 - reg_out_loss: 1.3436e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 35/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - cls_out_acc: 0.6318 - cls_out_auc: 0.6194 - cls_out_loss: 0.6175 - loss: 0.8252 - reg_out_loss: 1.3455e-04 - reg_out_mae: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 36/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - cls_out_acc: 0.6091 - cls_out_auc: 0.6193 - cls_out_loss: 0.6441 - loss: 0.8470 - reg_out_loss: 1.3432e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 37/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - cls_out_acc: 0.6091 - cls_out_auc: 0.6027 - cls_out_loss: 0.6313 - loss: 0.8379 - reg_out_loss: 1.3410e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 38/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - cls_out_acc: 0.6318 - cls_out_auc: 0.5473 - cls_out_loss: 0.6580 - loss: 0.8585 - reg_out_loss: 1.3431e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 39/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - cls_out_acc: 0.6505 - cls_out_auc: 0.6420 - cls_out_loss: 0.6295 - loss: 0.8280 - reg_out_loss: 1.3439e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 40/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - cls_out_acc: 0.6576 - cls_out_auc: 0.6239 - cls_out_loss: 0.6273 - loss: 0.8219 - reg_out_loss: 1.3427e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 41/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - cls_out_acc: 0.5903 - cls_out_auc: 0.6448 - cls_out_loss: 0.6256 - loss: 0.8170 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 42/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - cls_out_acc: 0.6466 - cls_out_auc: 0.6831 - cls_out_loss: 0.5943 - loss: 0.7872 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 43/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - cls_out_acc: 0.6310 - cls_out_auc: 0.6415 - cls_out_loss: 0.6146 - loss: 0.8102 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 44/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - cls_out_acc: 0.6427 - cls_out_auc: 0.6197 - cls_out_loss: 0.6304 - loss: 0.8142 - reg_out_loss: 1.3426e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 45/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - cls_out_acc: 0.6200 - cls_out_auc: 0.6110 - cls_out_loss: 0.6251 - loss: 0.8167 - reg_out_loss: 1.3451e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 46/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - cls_out_acc: 0.6122 - cls_out_auc: 0.6575 - cls_out_loss: 0.6080 - loss: 0.7984 - reg_out_loss: 1.3450e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 47/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - cls_out_acc: 0.6021 - cls_out_auc: 0.6442 - cls_out_loss: 0.6124 - loss: 0.7989 - reg_out_loss: 1.3422e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 48/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - cls_out_acc: 0.6388 - cls_out_auc: 0.6625 - cls_out_loss: 0.5991 - loss: 0.7884 - reg_out_loss: 1.3448e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 49/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - cls_out_acc: 0.6498 - cls_out_auc: 0.6716 - cls_out_loss: 0.6042 - loss: 0.7887 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 50/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - cls_out_acc: 0.6388 - cls_out_auc: 0.6732 - cls_out_loss: 0.5942 - loss: 0.7835 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 51/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - cls_out_acc: 0.6388 - cls_out_auc: 0.6606 - cls_out_loss: 0.5876 - loss: 0.7809 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 52/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - cls_out_acc: 0.6279 - cls_out_auc: 0.6596 - cls_out_loss: 0.5977 - loss: 0.7838 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 53/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - cls_out_acc: 0.6388 - cls_out_auc: 0.6910 - cls_out_loss: 0.5845 - loss: 0.7679 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 54/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - cls_out_acc: 0.6279 - cls_out_auc: 0.6959 - cls_out_loss: 0.5793 - loss: 0.7640 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 55/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - cls_out_acc: 0.6388 - cls_out_auc: 0.6808 - cls_out_loss: 0.5863 - loss: 0.7747 - reg_out_loss: 1.3445e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 56/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - cls_out_acc: 0.6200 - cls_out_auc: 0.6166 - cls_out_loss: 0.6151 - loss: 0.8018 - reg_out_loss: 1.3429e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 57/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - cls_out_acc: 0.6388 - cls_out_auc: 0.6489 - cls_out_loss: 0.6099 - loss: 0.7889 - reg_out_loss: 1.3425e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 58/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - cls_out_acc: 0.6060 - cls_out_auc: 0.6932 - cls_out_loss: 0.5777 - loss: 0.7587 - reg_out_loss: 1.3358e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 59/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - cls_out_acc: 0.6498 - cls_out_auc: 0.6919 - cls_out_loss: 0.5767 - loss: 0.7601 - reg_out_loss: 1.3395e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 60/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - cls_out_acc: 0.6576 - cls_out_auc: 0.6533 - cls_out_loss: 0.6007 - loss: 0.7870 - reg_out_loss: 1.3528e-04 - reg_out_mae: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 61/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - cls_out_acc: 0.6607 - cls_out_auc: 0.6727 - cls_out_loss: 0.5852 - loss: 0.7709 - reg_out_loss: 1.3315e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 62/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - cls_out_acc: 0.6498 - cls_out_auc: 0.6939 - cls_out_loss: 0.5753 - loss: 0.7612 - reg_out_loss: 1.3278e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 63/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - cls_out_acc: 0.6498 - cls_out_auc: 0.6959 - cls_out_loss: 0.5663 - loss: 0.7484 - reg_out_loss: 1.3263e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 64/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - cls_out_acc: 0.6685 - cls_out_auc: 0.6744 - cls_out_loss: 0.5788 - loss: 0.7636 - reg_out_loss: 1.3260e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 65/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - cls_out_acc: 0.6498 - cls_out_auc: 0.7298 - cls_out_loss: 0.5589 - loss: 0.7383 - reg_out_loss: 1.3220e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 66/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - cls_out_acc: 0.6795 - cls_out_auc: 0.7477 - cls_out_loss: 0.5290 - loss: 0.7184 - reg_out_loss: 1.3196e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 67/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - cls_out_acc: 0.6873 - cls_out_auc: 0.7772 - cls_out_loss: 0.5285 - loss: 0.7065 - reg_out_loss: 1.3188e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 68/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - cls_out_acc: 0.6717 - cls_out_auc: 0.6976 - cls_out_loss: 0.5654 - loss: 0.7560 - reg_out_loss: 1.3197e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 69/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - cls_out_acc: 0.6873 - cls_out_auc: 0.7373 - cls_out_loss: 0.5345 - loss: 0.7216 - reg_out_loss: 1.3299e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 70/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - cls_out_acc: 0.6685 - cls_out_auc: 0.7546 - cls_out_loss: 0.5349 - loss: 0.7217 - reg_out_loss: 1.3194e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 71/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - cls_out_acc: 0.6826 - cls_out_auc: 0.7296 - cls_out_loss: 0.5366 - loss: 0.7243 - reg_out_loss: 1.3178e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 72/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - cls_out_acc: 0.7092 - cls_out_auc: 0.7571 - cls_out_loss: 0.5234 - loss: 0.7065 - reg_out_loss: 1.3183e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 73/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - cls_out_acc: 0.6795 - cls_out_auc: 0.7758 - cls_out_loss: 0.5169 - loss: 0.6987 - reg_out_loss: 1.3208e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 74/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - cls_out_acc: 0.6982 - cls_out_auc: 0.7873 - cls_out_loss: 0.5120 - loss: 0.6963 - reg_out_loss: 1.3197e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 75/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - cls_out_acc: 0.7170 - cls_out_auc: 0.7779 - cls_out_loss: 0.5066 - loss: 0.6956 - reg_out_loss: 1.3258e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 76/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - cls_out_acc: 0.7092 - cls_out_auc: 0.8077 - cls_out_loss: 0.4740 - loss: 0.6592 - reg_out_loss: 1.3211e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 77/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - cls_out_acc: 0.7467 - cls_out_auc: 0.8138 - cls_out_loss: 0.4770 - loss: 0.6618 - reg_out_loss: 1.3140e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 78/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - cls_out_acc: 0.6982 - cls_out_auc: 0.7761 - cls_out_loss: 0.5026 - loss: 0.6961 - reg_out_loss: 1.3255e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 79/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - cls_out_acc: 0.7060 - cls_out_auc: 0.8011 - cls_out_loss: 0.4640 - loss: 0.6542 - reg_out_loss: 1.3172e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 80/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - cls_out_acc: 0.7467 - cls_out_auc: 0.8396 - cls_out_loss: 0.4407 - loss: 0.6218 - reg_out_loss: 1.3254e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 81/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - cls_out_acc: 0.7060 - cls_out_auc: 0.7856 - cls_out_loss: 0.4915 - loss: 0.6793 - reg_out_loss: 1.3089e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 82/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - cls_out_acc: 0.7436 - cls_out_auc: 0.7919 - cls_out_loss: 0.4779 - loss: 0.6680 - reg_out_loss: 1.3197e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 83/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - cls_out_acc: 0.7389 - cls_out_auc: 0.8127 - cls_out_loss: 0.4550 - loss: 0.6315 - reg_out_loss: 1.3160e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 84/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - cls_out_acc: 0.7170 - cls_out_auc: 0.8452 - cls_out_loss: 0.4456 - loss: 0.6249 - reg_out_loss: 1.3218e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 85/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - cls_out_acc: 0.6982 - cls_out_auc: 0.8179 - cls_out_loss: 0.4657 - loss: 0.6508 - reg_out_loss: 1.3107e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 86/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - cls_out_acc: 0.7874 - cls_out_auc: 0.8028 - cls_out_loss: 0.4889 - loss: 0.6736 - reg_out_loss: 1.3237e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 87/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - cls_out_acc: 0.7092 - cls_out_auc: 0.8377 - cls_out_loss: 0.4657 - loss: 0.6487 - reg_out_loss: 1.3218e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 88/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - cls_out_acc: 0.7170 - cls_out_auc: 0.7999 - cls_out_loss: 0.4679 - loss: 0.6561 - reg_out_loss: 1.3246e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 89/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - cls_out_acc: 0.7874 - cls_out_auc: 0.8597 - cls_out_loss: 0.4052 - loss: 0.5820 - reg_out_loss: 1.3078e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 90/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - cls_out_acc: 0.7467 - cls_out_auc: 0.8465 - cls_out_loss: 0.4276 - loss: 0.6102 - reg_out_loss: 1.3216e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 91/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - cls_out_acc: 0.7952 - cls_out_auc: 0.8352 - cls_out_loss: 0.4327 - loss: 0.6118 - reg_out_loss: 1.3068e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 92/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - cls_out_acc: 0.7952 - cls_out_auc: 0.8564 - cls_out_loss: 0.4033 - loss: 0.5795 - reg_out_loss: 1.3289e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 93/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - cls_out_acc: 0.7764 - cls_out_auc: 0.8407 - cls_out_loss: 0.4440 - loss: 0.6251 - reg_out_loss: 1.3178e-04 - reg_out_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 94/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - cls_out_acc: 0.7655 - cls_out_auc: 0.8433 - cls_out_loss: 0.4388 - loss: 0.6183 - reg_out_loss: 1.3090e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 95/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - cls_out_acc: 0.7576 - cls_out_auc: 0.8599 - cls_out_loss: 0.3859 - loss: 0.5627 - reg_out_loss: 1.3086e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 96/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - cls_out_acc: 0.7498 - cls_out_auc: 0.8621 - cls_out_loss: 0.4179 - loss: 0.5980 - reg_out_loss: 1.3077e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 97/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - cls_out_acc: 0.8061 - cls_out_auc: 0.8331 - cls_out_loss: 0.4098 - loss: 0.5917 - reg_out_loss: 1.3085e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 98/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - cls_out_acc: 0.7874 - cls_out_auc: 0.8549 - cls_out_loss: 0.4045 - loss: 0.5837 - reg_out_loss: 1.3081e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 99/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - cls_out_acc: 0.7201 - cls_out_auc: 0.8767 - cls_out_loss: 0.4013 - loss: 0.5795 - reg_out_loss: 1.3095e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 100/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - cls_out_acc: 0.7764 - cls_out_auc: 0.8471 - cls_out_loss: 0.3953 - loss: 0.5728 - reg_out_loss: 1.3045e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 101/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - cls_out_acc: 0.7874 - cls_out_auc: 0.8672 - cls_out_loss: 0.4034 - loss: 0.5758 - reg_out_loss: 1.3072e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 102/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - cls_out_acc: 0.8061 - cls_out_auc: 0.8857 - cls_out_loss: 0.3783 - loss: 0.5538 - reg_out_loss: 1.3089e-04 - reg_out_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 103/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - cls_out_acc: 0.7764 - cls_out_auc: 0.8581 - cls_out_loss: 0.3973 - loss: 0.5719 - reg_out_loss: 1.3048e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 104/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - cls_out_acc: 0.7952 - cls_out_auc: 0.8654 - cls_out_loss: 0.4011 - loss: 0.5757 - reg_out_loss: 1.2994e-04 - reg_out_mae: 0.0081 - learning_rate: 0.0010\n",
            "Epoch 105/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - cls_out_acc: 0.8249 - cls_out_auc: 0.8786 - cls_out_loss: 0.3864 - loss: 0.5624 - reg_out_loss: 1.2904e-04 - reg_out_mae: 0.0081 - learning_rate: 0.0010\n",
            "Epoch 106/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - cls_out_acc: 0.7686 - cls_out_auc: 0.8785 - cls_out_loss: 0.4012 - loss: 0.5759 - reg_out_loss: 1.2970e-04 - reg_out_mae: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 107/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - cls_out_acc: 0.8139 - cls_out_auc: 0.8953 - cls_out_loss: 0.3682 - loss: 0.5325 - reg_out_loss: 1.2873e-04 - reg_out_mae: 0.0080 - learning_rate: 0.0010\n",
            "Epoch 108/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - cls_out_acc: 0.8139 - cls_out_auc: 0.9101 - cls_out_loss: 0.3378 - loss: 0.5084 - reg_out_loss: 1.2922e-04 - reg_out_mae: 0.0081 - learning_rate: 0.0010\n",
            "Epoch 109/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - cls_out_acc: 0.7952 - cls_out_auc: 0.8917 - cls_out_loss: 0.3571 - loss: 0.5303 - reg_out_loss: 1.2951e-04 - reg_out_mae: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 110/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - cls_out_acc: 0.8171 - cls_out_auc: 0.8735 - cls_out_loss: 0.3765 - loss: 0.5488 - reg_out_loss: 1.2877e-04 - reg_out_mae: 0.0081 - learning_rate: 0.0010\n",
            "Epoch 111/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step - cls_out_acc: 0.8061 - cls_out_auc: 0.8925 - cls_out_loss: 0.3607 - loss: 0.5331 - reg_out_loss: 1.3237e-04 - reg_out_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 112/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - cls_out_acc: 0.7874 - cls_out_auc: 0.9095 - cls_out_loss: 0.3321 - loss: 0.5033 - reg_out_loss: 1.3331e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 113/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - cls_out_acc: 0.8139 - cls_out_auc: 0.8776 - cls_out_loss: 0.3770 - loss: 0.5513 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 114/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - cls_out_acc: 0.8249 - cls_out_auc: 0.8941 - cls_out_loss: 0.3604 - loss: 0.5301 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 115/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - cls_out_acc: 0.8171 - cls_out_auc: 0.8970 - cls_out_loss: 0.3374 - loss: 0.5064 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 116/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - cls_out_acc: 0.8358 - cls_out_auc: 0.8834 - cls_out_loss: 0.3702 - loss: 0.5419 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 117/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - cls_out_acc: 0.7952 - cls_out_auc: 0.9067 - cls_out_loss: 0.3452 - loss: 0.5145 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 118/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - cls_out_acc: 0.8171 - cls_out_auc: 0.9065 - cls_out_loss: 0.3307 - loss: 0.4977 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 119/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - cls_out_acc: 0.8061 - cls_out_auc: 0.8886 - cls_out_loss: 0.3508 - loss: 0.5178 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 120/120\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - cls_out_acc: 0.7874 - cls_out_auc: 0.9125 - cls_out_loss: 0.3301 - loss: 0.4946 - reg_out_loss: 1.3449e-04 - reg_out_mae: 0.0086 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting PyFunc cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting PyFunc cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train r_norm MSE: 0.000247\n",
            "Train Directional Accuracy: 0.873\n",
            "Saved predictions.csv with 10 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataframes (assuming X_test.csv and predicted_close.csv exist)\n",
        "try:\n",
        "    test_df_plot = pd.read_csv(\"X_test.csv\")\n",
        "    pred_df_plot = pd.read_csv(\"predictions.csv\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading file: {e}.\")\n",
        "    exit()\n",
        "\n",
        "# Convert 'Date' columns to datetime objects\n",
        "test_df_plot['Date'] = pd.to_datetime(test_df_plot['Date'])\n",
        "pred_df_plot['Date'] = pd.to_datetime(pred_df_plot['Date'])\n",
        "\n",
        "# Merge the dataframes based on the 'Date' column for plotting\n",
        "merged_df_for_plot = pd.merge(test_df_plot, pred_df_plot, on='Date', how='left')\n",
        "merged_df_for_plot.sort_values('Date', inplace=True)\n",
        "\n",
        "# Drop rows where actual High/Low or Predicted_Close might be missing (shouldn't happen if pipelines are aligned)\n",
        "# Correct the column name from 'Predicted_Close' to 'Close'\n",
        "merged_df_for_plot.dropna(subset=['Low', 'High', 'Close'], inplace=True)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "# Plot the actual High-Low range as a shaded area\n",
        "plt.fill_between(merged_df_for_plot['Date'],\n",
        "                 merged_df_for_plot['Low'],\n",
        "                 merged_df_for_plot['High'],\n",
        "                 color='grey', alpha=0.25, label='Actual High–Low Range (Test Set)')\n",
        "# Plot the predicted Close price\n",
        "# Correct the column name from 'Predicted_Close' to 'Close'\n",
        "plt.plot(merged_df_for_plot['Date'], merged_df_for_plot['Close'], color='blue', linewidth=2, label='Predicted Close')\n",
        "\n",
        "plt.title('Predicted Close vs Actual High–Low Range on Test Set')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "NdaVw1gtEMle",
        "outputId": "778e0596-b48f-4baa-de1d-5d9cb4834e87"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
